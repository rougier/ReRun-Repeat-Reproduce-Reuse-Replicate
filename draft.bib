@ARTICLE{Rougier:2017,
   author = {{Rougier}, N.~P. and {Hinsen}, K. and {Alexandre}, F. and {Arildsen}, T. and
	{Barba}, L. and {Benureau}, F.~C.~Y. and {Titus Brown}, C. and
	{de Buyl}, P. and {Caglayan}, O. and {Davison}, A.~P. and {Andr{\'e} Delsuc}, M. and
	{Detorakis}, G. and {Diem}, A.~K. and {Drix}, D. and {Enel}, P. and
	{Girard}, B. and {Guest}, O. and {Hall}, M.~G. and {Neto Henriques}, R. and
	{Hinaut}, X. and {Jaron}, K.~S and {Khamassi}, M. and {Klein}, A. and
	{Manninen}, T. and {Marchesi}, P. and {McGlinn}, D. and {Metzner}, C. and
	{Petchey}, O.~L. and {Ekkehard Plesser}, H. and {Poisot}, T. and
	{Ram}, K. and {Ram}, Y. and {Roesch}, E. and {Rossant}, C. and
	{Rostami}, V. and {Shifman}, A. and {Stachelek}, J. and {Stimberg}, M. and
	{Stollmeier}, F. and {Vaggi}, F. and {Viejo}, G. and {Vitay}, J. and
	{Vostinar}, A. and {Yurchak}, R. and {Zito}, T.},
    title = "{Sustainable computational science: the ReScience initiative}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1707.04393},
 primaryClass = "cs.DL",
 keywords = {Computer Science - Digital Libraries},
     year = 2017,
    month = jul,
   adsurl = {http://adsabs.harvard.edu/abs/2017arXiv170704393R},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{Wilson:2017,
  doi =          {10.1371/journal.pcbi.1005510},
  url =          {https://doi.org/10.1371/journal.pcbi.1005510},
  year =         2017,
  month =        {6},
  publisher =    {Public Library of Science ({PLoS})},
  volume =       13,
  number =       6,
  pages =        {e1005510},
  author =       {Greg Wilson and Jennifer Bryan and Karen Cranston and Justin
                  Kitzes and Lex Nederbragt and Tracy K. Teal},
  editor =       {Francis Ouellette},
  title =        {Good enough practices in scientific computing},
  journal =      {{PLOS} Computational Biology}
}

@inproceedings{Courtes:2015,
  TITLE =        {{Reproducible and User-Controlled Software Environments in
                  HPC with Guix}},
  AUTHOR =       {Court{\`e}s, Ludovic and Wurmus, Ricardo},
  BOOKTITLE =    {{2nd International Workshop on Reproducibility in Parallel
                  Computing (RepPar)}},
  YEAR =         2015,
}

@article{osc:2015,
  doi =          {10.1126/science.aac4716},
  url =          {https://doi.org/10.1126/science.aac4716},
  year =         2015,
  publisher =    {American Association for the Advancement of Science ({AAAS})},
  volume =       349,
  number =       6251,
  author =       {{Open Science Collaboration}},
  pages =        {aac4716--aac4716},
  title =        {Estimating the reproducibility of psychological science},
  journal =      {Science}
}

@article{Iqbal:2016,
  doi =          {10.1371/journal.pbio.1002333},
  url =          {https://doi.org/10.1371/journal.pbio.1002333},
  year =         2016,
  publisher =    {Public Library of Science ({PLoS})},
  volume =       14,
  number =       1,
  pages =        {e1002333},
  author =       {Shareen A. Iqbal and Joshua D. Wallach and Muin J. Khoury and
                  Sheri D. Schully and John P. A. Ioannidis},
  editor =       {David L Vaux},
  title =        {Reproducible Research Practices and Transparency across the
                  Biomedical Literature},
  journal =      {{PLOS} Biology}
}

@article{Peng:2011,
  doi =          {10.1126/science.1213847},
  url =          {https://doi.org/10.1126/science.1213847},
  year =         2011,
  publisher =    {American Association for the Advancement of Science ({AAAS})},
  volume =       334,
  number =       6060,
  pages =        {1226--1227},
  author =       {R. D. Peng},
  title =        {Reproducible Research in Computational Science},
  journal =      {Science}
}

@article{Mesirov:2010,
  doi =          {10.1126/science.1179653},
  url =          {https://doi.org/10.1126/science.1179653},
  year =         2010,
  publisher =    {American Association for the Advancement of Science ({AAAS})},
  volume =       327,
  number =       5964,
  pages =        {415--416},
  author =       {J. P. Mesirov},
  title =        {Accessible Reproducible Research},
  journal =      {Science}
}

@article{Schwab:2000,
  doi =          {10.1109/5992.881708},
  url =          {https://doi.org/10.1109/5992.881708},
  year =         2000,
  publisher =    {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume =       2,
  number =       6,
  pages =        {61--67},
  author =       {M. Schwab and N. Karrenbach and J. Claerbout},
  title =        {Making scientific computations reproducible},
  journal =      {Computing in Science {\&} Engineering}
}

@article{Sandve:2013,
  doi =          {10.1371/journal.pcbi.1003285},
  year =         2013,
  publisher =    {Public Library of Science ({PLoS})},
  volume =       9,
  number =       10,
  pages =        {e1003285},
  author =       {Geir Kjetil Sandve and Anton Nekrutenko and James Taylor and
                  Eivind Hovig},
  editor =       {Philip E. Bourne},
  title =        {Ten Simple Rules for Reproducible Computational Research},
  journal =      {{PLoS} Computational Biology}
}

@inproceedings{Durumeric:2014,
  doi =          {10.1145/2663716.2663755},
  url =          {https://doi.org/10.1145/2663716.2663755},
  year =         2014,
  publisher =    {{ACM} Press},
  author =       {Zakir Durumeric and Mathias Payer and Vern Paxson and James
                  Kasten and David Adrian and J. Alex Halderman and Michael
                  Bailey and Frank Li and Nicolas Weaver and Johanna Amann and
                  Jethro Beekman},
  title =        {The Matter of Heartbleed},
  booktitle =    {Proceedings of the 2014 Conference on Internet Measurement
                  Conference - {IMC} {\textquotesingle}14}
}

@article{Eklund:2016,
  doi =          {10.1073/pnas.1602413113},
  year =         2016,
  publisher =    {Proceedings of the National Academy of Sciences},
  volume =       113,
  number =       28,
  pages =        {7900--7905},
  author =       {Anders Eklund and Thomas E. Nichols and Hans Knutsson},
  title =        {Cluster failure: Why {fMRI} inferences for spatial extent
                  have inflated false-positive rates},
  journal =      {Proceedings of the National Academy of Sciences}
}

@article{Collberg:2016,
  author =       {Collberg, Christian and Proebsting, Todd A.},
  title =        {Repeatability in Computer Systems Research},
  journal =      {Commun. ACM},
  issue_date =   {March 2016},
  volume =       59,
  number =       3,
  year =         2016,
  issn =         {0001-0782},
  pages =        {62--69},
  numpages =     8,
  url =          {http://doi.acm.org/10.1145/2812803},
  doi =          {10.1145/2812803},
  acmid =        2812803,
  publisher =    {ACM},
  address =      {New York, NY, USA},
}

@misc{Goble:2016,
  author =       {Goble, Carole Anne},
  Howpublished = {Slides on
                  \href{https://www.slideshare.net/carolegoble/what-is-reproducibility-gobleclean}{slideshare}},
  title =        {What is reproducibility? The R* Brouhaha},
  year =         2016
}

@article{Mesnard:2016,
  author={O. Mesnard and L. A. Barba},
  journal={Computing in Science Engineering},
  title={Reproducible and Replicable Computational Fluid Dynamics: It's Harder Than You Think},
  year={2017},
  volume={19},
  number={4},
  pages={44-55},
  abstract={Completing a full replication study of the authors' previously published findings on bluff-body aerodynamics was harder than they thought, despite them having good reproducible-research practices, such as sharing their code and data openly. Here's what they learned from three years, four computational fluid dynamics codes, and hundreds of runs.},
  keywords={aerodynamics;computational fluid dynamics;bluff-body aerodynamics;code sharing;computational fluid dynamics codes;data sharing;replicable computational fluid dynamics;reproducible computational fluid dynamics;reproducible-research practices;Boundary conditions;Computational fluid dynamics;Computational modeling;Fluid dynamics;Reproducibility of results;Scientific computing;Two dimensional displays;CFD;computational fluid dynamics;reproducible research;scientific computing},
  doi={10.1109/mcse.2017.3151254},
  ISSN={1521-9615},
  month={},}


@article{Peng:2006,
  author =       {Peng, Roger D. and Dominici, Francesca and Zeger, Scott L.},
  title =        {Reproducible Epidemiologic Research},
  journal =      {American Journal of Epidemiology},
  volume =       163,
  number =       9,
  pages =        783,
  year =         2006,
  doi =          {10.1093/aje/kwj093},
  URL =          {http://dx.doi.org/10.1093/aje/kwj093},
}

@article{Claerbout:2000,
  author =       {Jon Claerbout, and Martin Karrenbach, and Matthias Schwab, },
  title =        {Making Scientific Computations Reproducible},
  journal =      {Computing in Science \& Engineering},
  volume =       2,
  issn =         {1521-9615},
  year =         2000,
  pages =        {61-67},
  doi =          {doi.ieeecomputersociety.org/10.1109/5992.881708},
  publisher =    {IEEE Computer Society},
}

@ARTICLE{Diethelm:2012,
  author =       {K. Diethelm},
  journal =      {Computing in Science Engineering},
  title =        {The Limits of Reproducibility in Numerical Simulation},
  year =         2012,
  volume =       14,
  number =       1,
  pages =        {64-72},
  doi =          {10.1109/mcse.2011.21},
  ISSN =         {1521-9615},
  month =        1,
}

@article{Donoho:2009,
  author =       {Donoho, David L. and Maleki, Arian and Rahman, Inam Ur and
                  Shahram, Morteza and Stodden, Victoria},
  title =        {Reproducible Research in Computational Harmonic Analysis},
  journal =      {Computing in Science {\&} Engineering},
  publisher =    {Institute of Electrical {\&} Electronics Engineers ({IEEE})},
  year =         2009,
  month =        {1},
  number =       1,
  volume =       11,
  pages =        {8--18},
  link =         {http://dx.doi.org/10.1109/mcse.2009.15},
  doi =          {10.1109/mcse.2009.15},
}

@Inbook{Crook:2013,
author="Crook, Sharon M.
and Davison, Andrew P.
and Plesser, Hans E.",
editor="Bower, James M",
title="Learning from the Past: Approaches for Reproducibility in Computational Neuroscience",
bookTitle="20 Years of Computational Neuroscience",
year="2013",
publisher="Springer New York",
address="New York, NY",
pages="73--102",
abstract="Reproducible experiments are the cornerstone of science: only observations that can be independently confirmed enter the body of scientific knowledge. Computational science should excel in reproducibility, as simulations on digital computers avoid many of the small variations that are beyond the control of the experimental biologist or physicist. However, in reality, computational science has its own challenges for reproducibility: many computational scientists find it difficult to reproduce results published in the literature, and many authors have met problems replicating even the figures in their own papers. We present a distinction between different levels of replicability and reproducibility of findings in computational neuroscience. We also demonstrate that simulations of neural models can be highly sensitive to numerical details, and conclude that often it is futile to expect exact replicability of simulation results across simulator software packages. Thus, the computational neuroscience community needs to discuss how to define successful reproduction of simulation studies. Any investigation of failures to reproduce published results will benefit significantly from the ability to track the provenance of the original results. We present tools and best practices developed over the past 2 decades that facilitate provenance tracking and model sharing.",
isbn="978-1-4614-1424-7",
doi="10.1007/978-1-4614-1424-7_4",
url="https://doi.org/10.1007/978-1-4614-1424-7_4"
}

@book{Hughes:1995,
    author = {Hughes, B. D.},
    title = {Random Walks and Random Environments},
    publisher = {Clarendon Press Oxford University Press},
    year = {1995},
    isbn = {9780198537885},
    address = {Oxford New York},
}


@article{Smith:2017,
   author = {{Smith}, A.~M and {E Niemeyer}, K. and {Katz}, D.~S and {Barba}, L.~A and
	{Githinji}, G. and {Gymrek}, M. and {Huff}, K.~D and {Madan}, C.~R and
	{Cabunoc Mayes}, A. and {Moerman}, K.~M and {Prins}, P. and
	{Ram}, K. and {Rokem}, A. and {Teal}, T.~K and {Valls Guimera}, R. and
	{Vanderplas}, J.~T},
    title = "{Journal of Open Source Software (JOSS): design and first-year review}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1707.02264},
 primaryClass = "cs.DL",
 keywords = {Computer Science - Digital Libraries, Computer Science - Software Engineering},
     year = 2017,
    month = jul,
   adsurl = {http://adsabs.harvard.edu/abs/2017arXiv170702264S},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@book{Schwalbe:2016,
  author    = "National Academies of Sciences, Engineering, and Medicine",
  editor    = "Michelle Schwalbe",
  title     = "Statistical Challenges in Assessing and Fostering the Reproducibility of Scientific Results: Summary of a Workshop",
  isbn      = "978-0-309-39202-0",
  doi       = "10.17226/21915",
  abstract  = "Questions about the reproducibility of scientific research have been raised in numerous settings and have gained visibility through several high-profile journal and popular press articles. Quantitative issues contributing to reproducibility challenges have been considered (including improper data measurement and analysis, inadequate statistical expertise, and incomplete data, among others), but there is no clear consensus on how best to approach or to minimize these problems. \n\nA lack of reproducibility of scientific results has created some distrust in scientific findings among the general public, scientists, funding agencies, and industries. While studies fail for a variety of reasons, many factors contribute to the lack of perfect reproducibility, including insufficient training in experimental design, misaligned incentives for publication and the implications for university tenure, intentional manipulation, poor data management and analysis, and inadequate instances of statistical inference. \n\nThe workshop summarized in this report was designed not to address the social and experimental challenges but instead to focus on the latter issues of improper data management and analysis, inadequate statistical expertise, incomplete data, and difficulties applying sound statistic inference to the available data. Many efforts have emerged over recent years to draw attention to and improve reproducibility of scientific work. This report uniquely focuses on the statistical perspective of three issues: the extent of reproducibility, the causes of reproducibility failures, and the potential remedies for these failures. \n",
  url       = "https://www.nap.edu/catalog/21915/statistical-challenges-in-assessing-and-fostering-the-reproducibility-of-scientific-results",
  year      = 2016,
  publisher = "The National Academies Press",
  address   = "Washington, DC"
}

@article{Collange:2015,
    author = {Collange, Sylvain and Defour, David and Graillat, Stef and Iakymchuk, Roman},
    title = {Numerical reproducibility for the parallel reduction on multi- and many-core architectures},
    journal = {Parallel Computing},
    publisher = {Elsevier {BV}},
    year = {2015},
    month = {nov},
    volume = {49},
    pages = {83--97},
    link = {https://doi.org/10.1016%2Fj.parco.2015.09.001,, http://dx.doi.org/10.1016/j.parco.2015.09.001},
    doi = {10.1016/j.parco.2015.09.001},
}

@article{Hines:2008,
    author = {Hines, M. L. and Carnevale, N. T.},
    title = {Translating network models to parallel hardware in {NEURON}},
    journal = {Journal of Neuroscience Methods},
    publisher = {Elsevier {BV}},
    year = {2008},
    month = {apr},
    number = {2},
    volume = {169},
    pages = {425--455},
    link = {https://doi.org/10.1016%2Fj.jneumeth.2007.09.010,, http://dx.doi.org/10.1016/j.jneumeth.2007.09.010},
    doi = {10.1016/j.jneumeth.2007.09.010},
}
