\documentclass[a4paper,11pt]{article}

% Wider margins (compared to default)
\usepackage[margin=2.5cm]{geometry}

% English support (typography and hyphenation)
\usepackage[american]{babel}
\usepackage{csquotes}

% Unicode encoding
\usepackage[utf8]{inputenc}

% Better default font (Libertine and Inconsolata)
\usepackage[ttscale=.875]{libertine}
\usepackage[scaled=0.96]{zi4}

% Biber
\usepackage[backend=biber,
            style=apa,
            maxcitenames=3,
            maxbibnames=99,
            apamaxprtauth=99,	
            natbib=true]{biblatex}
\DeclareLanguageMapping{american}{american-apa}
\bibliography{library.bib}

% Graphics
\usepackage{graphicx}


% Code Listing
\usepackage{listings}
\usepackage[framemethod=tikz]{mdframed}
\makeatletter
\def\mdf@@codeheading{Code Listings}
\define@key{mdf}{title}{\def\mdf@@codeheading{#1}}
\mdfdefinestyle{lstlisting}{%
  backgroundcolor=black!2.5,
  innertopmargin=2pt,
  middlelinewidth=0.75pt,
  outerlinewidth=9pt,
  outerlinecolor=white,
  innerleftmargin=10pt,
  innerrightmargin=10pt,
  leftmargin=0pt,
  rightmargin=0pt,
  rightline=false,
  leftline=false,
  bottomline=false,
  skipabove=\topskip,
  skipbelow=\topskip,
  roundcorner=0pt,
  singleextra={
    \node[text=black, % fill=white, draw,
          anchor=south west, yshift=-0.25pt, xshift=5pt,
          font=\footnotesize] at (O|-P) {\csname mdf@@codeheading\endcsname};},
  firstextra={
    \node[text=black, % fill=white, draw,
          anchor=south west, yshift=-0.5pt, xshift=5pt,
          font=\footnotesize] at (O|-P) {\csname mdf@@codeheading\endcsname};}
}

\lstset{ %
  basicstyle=\small\tt\linespread{0.75},
  language=Python,
  commentstyle=\color{gray},
  columns=fullflexible,
}

\lstnewenvironment{code}[2][]{%
  \lstset{#1}%
  \mdframed[style=lstlisting,title={#2}]%
}{\endmdframed}


%\usepackage{listings}
%\surroundwithmdframed[
%%  hidealllines=true,
%  linewidth=0.25pt,
%  linecolor=black!50,
%  backgroundcolor=black!4,
%  innerleftmargin=8pt,
%  innertopmargin=3pt,
%  innerbottommargin=3pt]{lstlisting}
%\lstset{ %
%  basicstyle=\small\tt\linespread{0.75},
%  language=Python,
%  commentstyle=\color{gray},
%  columns=fullflexible,
%}


% Hyperref
\usepackage{xcolor}
\definecolor{blendedblue}{rgb}{0.2, 0.2, 0.6}
\definecolor{blendedred}{rgb}{0.8, 0.2, 0.2}
\usepackage[bookmarks=true,
            breaklinks=true,
            pdfborder={0 0 0},
            citecolor=blendedblue,
            colorlinks=true,
            linkcolor=blendedblue,
            urlcolor=blendedblue,
            citecolor=blendedblue,
            linktocpage=false,
            hyperindex=true,
            linkbordercolor=white]{hyperref}
\usepackage{hyperref}
\hypersetup{colorlinks=true}


\title{Re-run, Repeat, Reproduce, Re-use, Replicate:\\Transforming Code into Scientific Contributions}
% \title{Run Python, run!}
% \title{The R Quintuplet (R$^5$)}


\author{Nicolas P. Rougier and Fabien C. Y. Benureau}
\date{\today}

\begin{document}
\maketitle
% -------------------------
\section*{Introduction (R$^{\mathbf 0}$)}

%Replication is a cornerstone of science. 
Reproducibility is a cornerstone of science. 
% Since science aims to discover general principles of how the world functions, 
% * <nicolas.rougier@inria.fr> 2017-04-24T15:49:43.902Z:
% 
% > Since science aims to discover general principles of how the world functions, 
% 
% 
% C'est un peu une déclaration à l'emporte pièce et je soupçconne qu'il y a une littérature énorme sur la définition de la science. Et à moins de vouloir s'aliéner toute l'astophysioque et la cosmologie, on pourrait au minimum étendre à l'univers.
% 
% ^ <fabien.benureau+overleaf@gmail.com> 2017-04-25T13:29:01.309Z:
% 
% Reopened by editing the source!
% From [wikipedia](https://en.wikipedia.org/wiki/World): "In a philosophical context, the world is the whole of the physical Universe, or an ontological world."
% 
% ^ <nicolas.rougier@inria.fr> 2017-04-25T13:45:04.565Z:
%
% Mouais.
%
% ^.
If an experimental result cannot be obtained more than once,
% it might be because of a fluke, a bias, a bug, a false positive or even a hack.
%it becomes, at best, nothing more than food for thought for future research. 
it merely becomes, at best, an observation that
may feed future research. 
Replication issues have received increased attention in recent years,
in the domain of medicine and psychology in particular.
One could think that computer science would mostly be shielded from such issues.
But precisely because it is easy to believe that
if a program runs once and gives expected results it will do so forever, 
crucial steps to transform working code into meaningful scientific contributions are rarely undertaken \citep{Collberg:2016}. 
Computer science is plagued by replication problems,
in part, precisely because it seems impervious to them.

In fact, a program can fail as a scientific contribution
in many different ways for many different reasons.
Borrowing the terms coined by \citeauthor{Goble:2016} \citep{Goble:2016},
for your program to contribute to Science,
you have to make sure it is
re-runnable (R$^1$),
repeatable (R$^2$),
reproducible (R$^3$),
re-usable (R$^4$)
and replicable (R$^5$).\\

Let us illustrate this with a very simple example,
a random walk written in Python:

\begin{code}{\textbf{\textsc{Listing 1:}} Random walk (R$^0$)}
import random

x = 0
for i in xrange(10):
    step = random.choice([-1,+1])
    x += step
    print x,
\end{code}
% That would be too easy if the program was commented...
% # randomly choose ten instances of either 1 or -1. 
% # compute the cumulative sum (the sum of all preceeding elements)

Executed, this program would display 
\begin{code}{Output}
-1  0 -1 -2 -1 -2 -3 -2 -1 -2 # with the steps being -1, +1, -1, -1, +1, -1, -1, +1, +1, -1
\end{code}

What could go wrong with such a simple program?\\
\vfill
Well...
\vfill


% -------------------------
\clearpage
\section*{Re-runnable (R$^{\mathbf 1}$)}

Have you ever try to re-run a program you wrote some years ago?
Frustratingly, it can often be surprisingly hard. 
Part of the problem is that technology is evolving at a fast pace
and you cannot  know in advance
how the system, the software and the libraries your program depends on will evolve.
Since you wrote the code,
you may have reinstalled or upgraded  your operating system.
The compiler, interpreter or set of libraries installed may have been replaced with newer versions. 
You may find yourself battling with
arcane issues of library compatibility---thoroughly orthogonal to your immediate research  goals---to execute again a code \emph{that worked perfectly before}. 
% "thoroughly orthogonal to your immediate research goals": possibly problematic

To be clear, it is impossible to write future-proof code,
as the best efforts can be stymied by the smallest change in one of the dependencies.
At the same time, modernizing an unmaintained ten-year-old code
can reveal itself to be an arduous and expensive undertaking,
with each change risking to affect the semantics of the program.

Rather trying to predict the future or painstakingly dusting off old code, 
an often easier solution is to recreate the old execution environment.
For this to happen however, 
the dependencies in terms of systems, software and libraries must be made clear enough.

A \emph{re-runnable} code is one that describes an execution environment in which it is executable with enough details to be recreated.
As shown by \citep{Collberg:2016}, this is far from being neither obvious nor easy.

% * <fabien.benureau+overleaf@gmail.com> 2017-05-08T18:09:47.037Z:
% 
% Wouldn't Collberg be better cited in R^2?
% 
% ^.
% if using random.choices, won't be runnable with anything <3.6
% if using itertools.accumulate, won't be runnable with anything <3.2
% although perhaps not the best syntax, we might want to keep the
% import mod
% mod.function 
% syntax for both random and intertools
%
% Problem with current code is that it is highly inefficient now (compared to R0)
\begin{code}{\textbf{\textsc{Listing 2:}} Random walk (R$^1$)}
# Tested with Python 3
import random

walk, total = [], 0
for i in range(10):
    step = random.choice([-1,+1])     
    total += step
    walk.append(total)
    
print(walk)
\end{code}

In our case, the R$^0$ version of our tiny walker seems to imply
that any version of Python would be fine.
This not the case because it uses the print {\em instruction} and the {\tt xrange} operator, both specific to Python 2.
The print {\em instruction}, available in Python 2 (still widely used, will stop to be supported in 2020), 
has been deprecated in Python 3 (first released in 2008, almost a decade ago)
in favor or a  print {\em function}.
The {\tt xrange} operator has been replaced by the {\tt range} operator in Python 3.
In order to try to future-proof the code a bit, we might as well target Python 3, as is done in the R$^1$ version.
Incidentally, it remains compatible with Python 2.\\

But whatever the version chosen,
the crucial step here is to document it.


% \clearpage
\section*{Repeatable (R$^{\mathbf 2}$)}

% * <fabien.benureau+overleaf@gmail.com> 2017-04-27T06:18:15.753Z:
% 
% - 
% 
% Ok, so I am not sure that the parameter talk should be here. It should be in reproducible. 
% 
% ^.

The code is running and producing the expected results. 
The next step is to make sure that you can produce the same output over successive runs of your program, should you want to. 
In other words, the next step is to make your program deterministic,  producing {\em repeatable} output. 
Such repeatability is useful. 
If a run of the program produces a particularly puzzling results,  it allows you to scrutinize any step of the execution of the program by re-running it again. 
It is also the easiest way to prove that the program did indeed produce the published results.
Such repeatability is not always possible or easy \cite{Diethelm:2012}.
But for sequential programs not depending on exotic hardware, it often comes down to controlling the initialization of the pseudo-random number generators (RNG).\\ 

For our program, that means setting the seed of the {\tt random} module. We may also want to save the output of the program to a file, so that we can easily verify that consecutive runs do produce the same output; eyeballing differences is unreliable and  time-consuming (and therefore won't be done systematically).

\begin{code}{\textbf{\textsc{Listing 3:}} Random walk (R$^2$)}
# Tested with Python 3
import random

random.seed(0) # RNG initialization

walk, total = [], 0
for i in range(10):
    step = random.choice([-1,+1])     
    total += step
    walk.append(total)
    
print(walk)
with open("results.txt", "w") as file: # Saving output to disk
    file.write(str(walk))
\end{code}

Setting seeds is not without danger. 
Using 439 as a seed in the previous program would result in ten consecutive +1 steps, which---although a perfectly valid random walk---lend itself to gross misinterpretations of the overall dynamic of the algorithm. 
Verifying that the qualitative aspects of the results and the conclusion we make are not tied to a specific initialization of the pseudo-random generator is an integral part of any scientific undertaking in computational science; 
this is usually done by repeating the simulations multiple times with different seeds.  

%Determinism is a tool that allow to study bugs and spurious or unexpected behavior. 
%Determinism is also critical for other to reproduce and study your results. 
% talk about controversy about setting seeds

% For example, you can play with some parameters and
% find a specific set that produce interesting results that you save to a file.
% In the meantime, you continue playing with parameters in order get new results.
% But what if you want to come back to this one specific result you just saved?
% Did you save as well the set of parameters tied to this specific results? 
% This kind of situation happens quite regularly in the scientific literature \cite{Claerbout:2000} 
% such that in some case, it is virtually impossible
% to find the set of parameters that has been used to produce this or that figure.
% If you're note careful enough, this will happen to you as well.\\


% \clearpage
\section*{Reproducible (R$^{\mathbf 3}$)}

The R$^2$ code seems fine enough, but it hides several problems that come to light when trying to {\em reproduce} results.
In the strongest sense, a code is said to be {\em reproducible} if the same results it produced in the past can be re-obtained by someone else.
As explained by \citeauthor{Mesnard:2016} \citep{Mesnard:2016}, reproducibility is harder than you think. 
For instance, our R$^2$ program will not produce the same results for everyone. It will, because it is repeatable, produce the same results over repeated executions.
But it will not do so over different execution environments. The cause is found in a change that occurred in the pseudo-random number generator between CPython 3.2 and CPython 3.3. 
Executed with CPython 3.2 or older, the code will produce the sequence 1, 2, 1, 2, 3, 4, 5, 6, 7, 6. But with CPython 3.3 or newer, it will produce 1, 2, 1, 0, 1, 0, 1, 0, -1, 0.
Reproducibility impose to specify dependencies more precisely than re-runnability: the exact versions that were used must be documented. The platform should also be described as well: CPU architecture, operating system version, endianness, etc., as well as any defaults you may have set that might have an impact.
Because of the increasing complexity of our computational stacks, retrieving and deciding what is pertinent might be difficult. A best effort must be made.\\

Here, in addition to specifying the exact Python version and platform details, a short unit test is provided, that allows the code to verify its own reproducibility. Should this test fail, then there is little hope of reproducing the results. If it does not fail, problems may still be present. 
A second problem present in the R$^2$ program is that it does not store the parameters used along with the results. Therefore, should the code change after the production of the results, someone provided with the result file will not be able to know which seed was used to produce it. In R$^3$, the seed is stored in the name of the result file.

%\begin{itemize}
%\itemsep 0em
%\item Python 3
%\item Python 3.6
%\item {Python 3.6.1 (default, Mar 28 2017, 10:33:50) \\
%      {\tt [GCC 4.2.1 Compatible Apple LLVM 8.1.0 (clang-802.0.38)] on darwin}}
%\item {Python 3.6.1 (default, Mar 28 2017, 10:33:50) \\
%      {\tt [GCC 4.2.1 Compatible Apple LLVM 8.1.0 (clang-802.0.38)] on darwin}\\
%      {\tt configuration variables: -std=c99 -Wextra -Wno-unused-result -Wno-unused-parameter -Wno-missing-field-initializers ...}}
%\end{itemize}

% Adding license for diffusion
% Lorena Barba example (Science blog)

\begin{code}{\textbf{\textsc{Listing 4:}} Random walk (R$^3$)}
# Copyright (c) 2017 Nicolas P. Rougier and Fabien C.Y. Benureau
# Release under the BSD 2-clause license
# Tested with CPython 3.6 / macOS 10.12.4 / 64 bits architecture
import random
from itertools import accumulate

def walk(n):
    """ Random walk for n steps """
  
    steps = [-1 if random.uniform(-1,+1) < 0 else +1 for i in range(n)]
    return list(accumulate(steps))

if __name__ == '__main__':
    # Unit test
    random.seed(1)
    assert walk(10) == [-1, 0, 1, 0, -1, -2, -1, 0, -1, -2]

    # Random walk for 10 steps
    seed = 1
    random.seed(seed)
    x = walk(10)
    
    # Display & save results
    print(x)
    with open("results-R3-%d.txt" % seed, "w") as file:
        file.write(str(x))
\end{code}

Finally, a crucial condition to making a code reproducible is making it available. As shown in \citep{Collberg:2016}, code is often not available, or available upon request. The latter may seem sufficient, but changes in email address,  career or retirement can make the code just as unavailable. Code \emph{and input and result files} should be available with the published article, as supplementary data, or through a DOI link to a scientific repository such as Figshare or Zenodo.
Providing results files is important: it allows other researchers to easily compare the results they obtains with the one used to generate the figure in the article. Comparing figures directly can be cumbersome and often only allows to conclude about a qualitative similarity.\\

To recap, reproducibility imposes stronger conditions than re-runnability. Dependencies and platforms must be described as precisely and a specifically as possible. Unit tests are a good way to embed self-diagnostics of reproducibility in the code. Results must be accompanied with the parameters and inputs used to produce them. And the code, and the data files behind the figure must be made available. 


% \clearpage
\section*{Re-usable (R$^{\mathbf 4}$)}

Making your program re-usable means it can be used by people outside your lab,
using possibly different environment, different parameters or different data.
If people start using your program, they will most likely report bugs or malfunctions they encountered while using your program.
If you're lucky enough, they will even propose you bugfix, hence improving the overall quality and correctness of your software.
In other words, if your program is re-usable and is re-used, it is alive.
As such, and as for any other living being, it will evolve and mutate to adapt to its environment.
This process will ensure long-term reproducibility to the extent people continue using and maintaining the program.\\

However, making your program to be re-usable by others requires a little work. If it is natural, when one writes a program for oneself, to make implicit choices that suit one needs, such implicit choices won't resist the will of a user community. For example, having magic numbers or ill-defined constants in your program might be cumbersome for others. Similarly, it might be acceptable to not have a proper documentation when you're the only user (actually it might not be acceptable because the you now and the you in six months are two different persons), but other users want to know precisely how to use this or that function and what it does exactly.\\


If we look back at our random walker, we can list all the implicit choices that have been made:
\begin{itemize}
\item Step number has been hard-coded (magic number 10)
\item Step size has been fixed to 1
\item Initial position has been set to 0
\item No possibility of using a user-specified random seed
\item Only one run can be started at once
\item Walker walk along a single dimension
\item ...
\end{itemize}
However, we won't try to implement all these features at once, but only giving the possibility for a user to implement them if needed.


\begin{code}{\textbf{\textsc{Listing 5:}} Random walk (R$^4$)}
# Copyright (c) 2017 Nicolas P. Rougier and Fabien C.Y. Benureau
# Release under the BSD 2-clause license
# Tested with Python 3.6 / Numpy 1.12.0 / macOS 10.12.4 / 64 bits architecture
import random
import numpy as np

def walk(rng, n):
    """ Random walk for n steps """

    steps = 2*(rng.uniform(-1,+1,n) > 0) - 1
    return steps.cumsum().tolist()

def rng(seed):
    """ Return a random number generator initialized with seed """ 
    
    rng = np.random.RandomState()
    rng.seed(seed)
    return rng

def test():
    """ Unit tests """

    return walk(rng(seed=1), 10) == [-1, 0, 1, 0, -1, -2, -1, 0, -1, -2]

if __name__ == '__main__':
    import argparse
    parser = argparse.ArgumentParser("Random walk")
    parser.add_argument('--seed', type=int, default=1,
                        help='Seed for random number generator ')
    parser.add_argument('n', type=int, default=10,
                        help='Number of step(s) to walk')
    args = parser.parse_args()

    # Random walk for n steps
    x = walk(rng(args.seed), args.n)

    # Display & save results
    print("Seed:", args.seed)
    print("Number of steps:", args.n)
    print("Result:",  x)
    with open("results-R5-%d.txt" % seed, "w") as file:
        file.write("Version: R5")
        file.write("Seed: %d" % args.seed)
        file.write("Steps number: %d" % args.n)
        file.write("Output: %s" % str(x))
\end{code}


% \clearpage
\section*{Replicable (R$^{\mathbf 5}$)}

Having made a software re-usable by others should offer a decent protection against bugs. Unfortunately, this is not always the case and some recent cases have demonstrated the tremendous impact a bug can have in Science \citep{Eklund:2016} or in our every-day life \citep{Durumeric:2014}.
This is why, as explained by Peng et al. \cite{Peng:2006}, {\em the replication of important findings by multiple independent investigators is fundamental to the accumulation of scientific evidence}.
%Replicability is the assumption that any article that does not provide the code source makes: that the description it provides of the algorithms is sufficiently precise and complete to re-obtain the results it presents.

In our case, the replication of the random walk brings some unexpected discrepancies between the original Python version and the replicated Numpy version.
The reason is to be found in a differences in the respective implementations of the RNG between Python and Numpy.
As explained in the \href{https://docs.python.org/3.6/library/random.html}{Python documentation}, {\em Python uses the Mersenne Twister as the core generator. It produces 53-bit precision floats
and has a period of 2**19937-1.
The underlying implementation in C is both fast and threadsafe.}
Numpy RNG is also based on the Mersenne Twister generator but there are differences in the way seed is interpreted when initializing the generator.
Fortunately, Both Numpy and Python offer access to the internal state and we can {\em fix} it to make the behavior of one RNG to match the other RNG.
Here, we want to make the Numpy RNG to match the Python RNG behvior.

\begin{code}{\textbf{\textsc{Listing 6:}} Random walk (R$^5$)}
# Copyright (c) 2017 Nicolas P. Rougier and Fabien C.Y. Benureau
# Release under the BSD 2-clause license
# Tested with Python 3.6 / Numpy 1.12.0 / macOS 10.12.4 / 64 bits architecture
import random
import numpy as np

def walk(rng, n):
    """ Random walk for n steps """

    steps = 2*(rng.uniform(-1,+1,n) > 0) - 1
    return steps.cumsum().tolist()

def rng(seed):
    """ Return a random number generator initialized with seed """ 
    
    rng = random.Random()
    rng.seed(seed)
    _, keys, _ = rng.getstate()
    rng = np.random.RandomState()
    state = rng.get_state()
    rng.set_state((state[0], keys[:-1], state[2], state[3], state[4]))
    return rng

if __name__ == '__main__':
    # Unit test
    assert walk(rng(seed=1), 10) == [-1, 0, 1, 0, -1, -2, -1, 0, -1, -2]

    # Random walk for 10 steps
    seed = 1
    x = walk(rng(seed=2), 10)

    # Display & save results
    print(x)
    with open("results-R4-%d.txt" % seed, "w") as file:
        file.write(str(x))
\end{code}



% \clearpage
\section*{Conclusion}

Using a very simple random walk example using Python, we've seen a variety of pitfalls of writing scientific code. The R$^0$ form, while easy to write and simple to understand is not a good scientific code while the full-fledge R$^{4}$ form is much preferred but requires a fair amount of work that might be unacceptable in some circumstances. $R^3$ form seems to be an acceptable compromise and should be accepted as the minimum scientific standard. This means this should be actually checked by reviewers and publishers when code is part of a work worth to be published. But it's hardly the case today.\\

The choice of the Python programming language to illustrate our point was not arbitrary. In less than a decade, Python has become one the few programming language of Science (together with R and Matlab). It is now used by a huge and growing number of researchers from different domains, having various experience and background in computer science. The readability and ease of use of Python make it a premium choice for new comers. But this is precisely this apparent simplicity that might hinder correct implementation. Inexperienced people may think any working code is a scientific code, but, as we've explained, this is simply not true.


% Writing reproducible software requires both knowledge and experience. For the former, there are plenty of resources online or onsite.

% underscore that compared to psy/bio/etc. the replication issues of CS are easily (reasonably) managed: good solutions that (mostly) works exist right now.

\renewcommand*{\bibfont}{\small}
\printbibliography[title=References]


\end{document}

